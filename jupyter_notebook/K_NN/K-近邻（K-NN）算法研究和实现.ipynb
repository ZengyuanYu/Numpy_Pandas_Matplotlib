{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN算法理解\n",
    "#### 1.介绍\n",
    "k近邻算法基于分类和回归的方法，工作原理为：已知一个样本数据集合，称之为训练样本集，且每个数据都存在有标签，即每个数据所属分类我们是知道的。在此基础上训练，再输入没有标签的新数据，将新的数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本最相似（最近邻）的分类标签。一般来说，我们只选择样本数据集中前k个最相似的数据，这就是k-近邻算法中k的出处，通常k是不大于20的整数。最后，选择k个最相似数据中出现次数最多的分类，作为新数据的分类。\n",
    "　\n",
    "举一个具体的例子，使用k-近邻算法分类一部影片是爱情片还是动作片。\n",
    "> 表中每部电影的打斗次数，接吻次数及电影的类型\n",
    "\n",
    "| 电影名称     | 打斗次数| 接吻次数 | 类型|\n",
    "|--------|---------|---------|:-------:|\n",
    "| 电影1| 1|101| 爱情片      |\n",
    "| 电影2| 5| 89 |爱情片      |\n",
    "| 电影3| 108| 5 | 动作片    |\n",
    "| 电影4| 115| 8 | 动作片    |\n",
    "表中就是我们已有的数据集合，也就是训练样本集。这个数据集有两个特征，即打斗镜头数和接吻镜头数。除此之外，我们也知道每个电影的所属类型，即分类标签。用肉眼粗略地观察，接吻镜头多的，是爱情片。打斗镜头多的，是动作片。*现在给一个新的电影，给出接吻次数和打斗次数，我们判断属于哪一类的电影*。k-近邻算法是靠已有的数据来度量距离判断未知的数据。\n",
    "#### 2.距离度量\n",
    "我们已经知道k-近邻算法根据特征比较，然后提取样本集中特征最相似数据(最邻近)的分类标签。那么，如何进行比较呢？比如，我们还是以表格为例，怎么判断红色圆点标记的电影所属的类别呢？\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**散点图解释**\n",
    "1. `scatter()` 散点图的绘制 其中输入可以是单点坐标也可以是一个list\n",
    "2. `color=' '` 设置点的颜色使用\n",
    "3. `annotate()` 是在图上添加描述\n",
    "4. `xlabel()` 设置横轴名称，同理纵轴使用 `ylabel()` 设置\n",
    "5. `xlim()` 设置横轴数值范围， 同理纵轴使用 `ylim()` 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#爱情片\n",
    "x_1 = [1, 5, ]\n",
    "y_1 = [101, 89]\n",
    "#动作片\n",
    "x_2 = [108, 105]\n",
    "y_2 = [5, 8]\n",
    "#待预测电影\n",
    "x_pre = 101\n",
    "y_pre = 20\n",
    "#绘制\n",
    "plt.scatter(x_1, y_1, color='b')\n",
    "plt.scatter(x_2, y_2, color='r')\n",
    "plt.scatter(x_pre, y_pre, color='y')\n",
    "#给x_pre,y_pre添加描述\n",
    "plt.annotate('pre(101, 20)' ,xy=(x_pre,y_pre),xycoords='data',xytext=(+20,-0),\n",
    "            textcoords='offset points', fontsize=10,\n",
    "            arrowprops=dict(arrowstyle='->'))\n",
    "#设置x,y轴标签\n",
    "plt.xlabel('fit times')\n",
    "plt.ylabel('kiss times')\n",
    "#设置横轴坐标值范围\n",
    "plt.xlim((0, 140))\n",
    "plt.ylim((0, 120))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从散点图可以大致的推断出，这个pre点是属于动作片的，因为距离红色点更近。那么K-近邻算法是怎么判断这个距离的？没错，就是使用距离度量。因为电影的判断标准是*打斗次数*和*接吻次数*2个特征，也就是2维实数向量空间，可以使用两点计算公式：\n",
    "$$|AB| = \\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$$\n",
    "- **MarkDown公式编辑解释**\n",
    "    1. `$公式$` 表示行内公式，而 `$$公式$$` 表示在新的一行写公式\n",
    "    2. 开方使用 `\\sqrt{x}`,例：$\\sqrt{x}$\n",
    "    3. 上下标，`x^2`,`x_2`为上下标，比如 $x^2+x_2$\n",
    "------\n",
    "通过计算，可以得到如下结果：\n",
    "- (101,20)->动作片(108,5)的距离约为16.55\n",
    "- (101,20)->动作片(115,8)的距离约为18.44\n",
    "- (101,20)->爱情片(5,89)的距离约为118.22\n",
    "- (101,20)->爱情片(1,101)的距离约为128.69\n",
    "\n",
    "通过计算可知，红色圆点标记的电影到动作片 (108,5)的距离最近，为16.55。如果算法直接根据这个结果，判断该红色圆点标记的电影为动作片，这个算法就是最近邻算法，而非k-近邻算法。那么k-近邻算法是什么呢？k-近邻算法步骤如下：\n",
    "1. 计算已知类别数据集中的点与当前点之间的距离\n",
    "2. 按照距离递增排列\n",
    "3. 选取与当前点距离最小的k个点\n",
    "4. 确定前k个点所在类别的出现频率\n",
    "5. 返回前k个点所出现频率最高的类别作为当前点的预测分类\n",
    "\n",
    "比如，现在我这个k值取3，那么在电影例子中，按距离依次排序的三个点分别是动作片(108,5)、动作片(115,8)、爱情片(5,89)。在这三个点中，动作片出现的频率为三分之二，爱情片出现的频率为三分之一，所以该红色圆点标记的电影为动作片。这个判别过程就是k-近邻算法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Python代码实现\n",
    "我们已经知道了k-近邻算法的原理，那么接下来就是使用Python实现该算法，依然以电影分类为例。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) 数据集的准备\n",
    "\n",
    "对表格中的数据，可使用numpy直接创建，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import operator\n",
    "\"\"\"\n",
    "函数说明：根据表格内容创建数据集\n",
    "\n",
    "parameters:\n",
    "    无\n",
    "return:\n",
    "    group - 数据集\n",
    "    labels- 分类标签\n",
    "\"\"\"\n",
    "def createDataSet():\n",
    "    #四组二维特征\n",
    "    group = np.array([\n",
    "        [1, 101],\n",
    "        [5, 89],\n",
    "        [108, 5],\n",
    "        [115, 8]\n",
    "    ])\n",
    "    #四组特征的标签\n",
    "    labels = ['爱情片', '爱情片', '动作片', '动作片']\n",
    "    return group, labels\n",
    "# if __name__ == '__main__':\n",
    "#     #创建数据集\n",
    "#     group, labels = createDataSet()\n",
    "#     #打印数据集\n",
    "#     print(group, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) K-近邻算法\n",
    "\n",
    "根据两点距离公式，计算距离，选择距离最小的前k个点，并返回分类结果。\n",
    "1. `shape[0]` 返回dataSet的行数，比如 `createDataSet()` 创建的group是一个[4x1]的矩阵,则 `group.shape[0]` 的值为4\n",
    "2. `np.tile()` 是一种元素复制方法，比如`a = [1,2]`,则 `np.tile(a, 2)` 结果为`a = [1,2,1,2]`,更高级的 `np.tile(a, [4,1])`结果变成 `4x1` 的矩阵`[[1,2],[1,2],[1,2],[1,2]]`\n",
    "3. `sum()` 函数为按行 `sum(1)` 和按列 `sum(0)`\n",
    "4. `argsort()` 为将元素按照从小到达排序之后返回其索引值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_nn(inX, dataSet, labels, k):\n",
    "    #shape[0]获取数据集的行数\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    #\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    sqDiffMat = diffMat**2\n",
    "    #sum()所有元素相加，sum(0)按列相加，sum(1)按行相加\n",
    "    sqDistances = sqDiffMat.sum(axis=1)\n",
    "    #开方，计算出距离\n",
    "    distances = sqDistances**0.5\n",
    "    #返回distances中元素从小到大排序后的索引值\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    #定义一个记录类别次数的字典\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        #取前k个元素的类别\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        #dict.get(key,default=None),字典的get()方法,返回指定键的值,如果值不在字典中返回默认值。\n",
    "        #计算类别次数\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    #key=operator.itemgetter(1)根据字典的值进行排序\n",
    "    #key=operator.itemgetter(0)根据字典的键进行排序\n",
    "    #reverse降序排序字典\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    #返回次数最多的类别,即所要分类的类别\n",
    "    return sortedClassCount[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) 进行实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import time\n",
    "    start = time.time()\n",
    "    #创建数据集\n",
    "    group, labels = createDataSet()\n",
    "    print(group, \"\\n\", labels)\n",
    "    #测试集\n",
    "    test = [1, 80]\n",
    "    #K-NN分类器\n",
    "    test_class = k_nn(test, group, labels, 3)\n",
    "    #打印输出结果\n",
    "    print(test_class)\n",
    "    print(\"run time: %s s\" %(time.time()-start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-NN算法实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.多维距离和算法流程\n",
    "\n",
    "由1.3的代码实现可以得出，这种最近邻的度量标准是work的，但是电影的列子是2维的，如果特征更多上升到高维呢？那就需要使用欧式距离（欧几里得度量）。\n",
    "        $$d(\\mathbf{p},\\mathbf{q})=d(\\mathbf{q},\\mathbf{p})=\\sqrt{(q_1-p-1)^2+(q_2-p-2)^2+(q_3-p-3)^2+...+(q_n-p-n)^2}=\\sqrt{\\sum_{m=0}^n {(q_i-p_i)^2} }$$\n",
    "分类器并不会得到百分百正确的结果，我们可以使用多种方法检测分类器的正确率。此外分类器的性能也会受到多种因素的影响，如分类器设置和数据集等。不同的算法在不同数据集上的表现可能完全不同。为了测试分类器的效果，我们可以使用已知答案的数据，当然答案不能告诉分类器，检验分类器给出的结果是否符合预期结果。通过大量的测试数据，我们可以得到分类器的错误率-分类器给出错误结果的次数除以测试执行的总数。错误率是常用的评估方法，主要用于评估分类器在某个数据集上的执行效果。\n",
    "K-近邻算法的主要流程为：\n",
    "- 1.收集数据：可以使用爬虫或者现有的数据。一遍数据存放在txt文本中，按照一定的格式进行存储，便于解析和处理；\n",
    "- 2.数据准备：使用Python的列表和字典预处理数据；\n",
    "- 3.分析数据：数据分析一般使用matplotlib可视化；\n",
    "- 4.测试算法：计算错误率\n",
    "- 5.使用算法：错误率在一个范围内之内，运行K-NN进行算法分类\n",
    "#### 2.问题描述和数据准备\n",
    "- 问题描述\n",
    "海伦女士一直使用在线约会网站寻找适合自己的约会对象。尽管约会网站会推荐不同的任选，但她并不是喜欢每一个人。经过一番总结，她发现自己交往过的人可以进行如下分类：\n",
    "    1. 不喜欢的人\n",
    "    2. 魅力一般的人\n",
    "    3. 极具魅力的人\n",
    "海伦收集约会数据已经有了一段时间，她把这些数据存放在文本文件K_NNData.txt中，共1000行。\n",
    "海伦收集的样本数据主要包含以下3种特征：\n",
    "    1. 每年获得的飞行常客里程数\n",
    "    2. 玩视频游戏所消耗的时间百分比\n",
    "    3. 每周消耗的冰激凌公升数\n",
    "------\n",
    "**K_NNData.txt中文件格式**\n",
    "![图片](/home/yu/Templates/Numpy_Pandas_Matplotlib/jupyter_notebook/Data格式.png)\n",
    "- 数据解析\n",
    "在将上述特征数据输入到分类器前，必须将待处理的数据的格式改变为分类器可以接收的格式。分类器接收的数据是什么格式的？要将数据分类两部分，即特征矩阵和对应的分类标签向量。创建名为file2matrix的函数，以此来处理输入格式问题。编写代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "函数说明:打开并解析文件，对数据进行分类：1代表不喜欢,2代表魅力一般,3代表极具魅力\n",
    "\n",
    "Parameters:\n",
    "    filename - 文件名\n",
    "Returns:\n",
    "    returnMat - 特征矩阵\n",
    "    classLabelVector - 分类Label向量\n",
    "\"\"\"\n",
    "def file2matrix(filename):\n",
    "    #打开文件\n",
    "    fr = open(filename)\n",
    "    #读取文件所有内容\n",
    "    array0Lines = fr.readlines()\n",
    "    #得到文件行数\n",
    "    numberOfLines = len(array0Lines)\n",
    "    #定义返回矩阵，解析完成的数据：numberOfLines行，3列\n",
    "    returnMat = np.zeros((numberOfLines, 3))\n",
    "    #返回分类标签向量\n",
    "    classLabelVector = []\n",
    "    #行的索引值\n",
    "    index = 0\n",
    "    for line in array0Lines:\n",
    "        #s.strip(rm)，当rm空时,默认删除头尾空白符(包括'\\n','\\r','\\t',' ')\n",
    "        line = line.strip()\n",
    "        #使用s.split(str=\"\",num=string,cout(str))将字符串根据'\\t'分隔符进行切片\n",
    "        listFromLine = line.split('\\t')\n",
    "        #将数据前三列提取出来,存放到returnMat的NumPy矩阵中,也就是特征矩阵\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "       #根据文本中标记的喜欢的程度进行分类,1代表不喜欢,2代表魅力一般,3代表极具魅力\n",
    "        if listFromLine[-1] == 'didntLike':\n",
    "            classLabelVector.append(1)\n",
    "        elif listFromLine[-1] == 'smallDoses':\n",
    "            classLabelVector.append(2)\n",
    "        elif listFromLine[-1] == 'largeDoses':\n",
    "            classLabelVector.append(3)\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector \n",
    "filename = \"K_NNData.txt\"\n",
    "datingDataMat, datingLabels = file2matrix(filename)\n",
    "print(datingDataMat.shape)\n",
    "print(len(datingLabels))\n",
    "print(datingDataMat,\"\\n\",datingLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到，我们已经顺利导入数据，并对数据进行解析，格式化为分类器需要的数据格式。接着我们需要了解数据的真正含义。可以通过友好、直观的图形化的方式观察数据。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "函数说明:可视化数据\n",
    "\n",
    "Parameters:\n",
    "    datingDataMat - 特征矩阵\n",
    "    datingLabels - 分类Label\n",
    "Returns:\n",
    "    无\n",
    "Modify:\n",
    "    2017-03-24\n",
    "\"\"\"\n",
    "def showdatas(datingDataMat, datingLabels):\n",
    "    #设置汉字格式\n",
    "    font = FontProperties(fname=r\"/usr/share/fonts/truetype/arphic/ukai.ttc\")\n",
    "    #将fig画布分隔成1行1列，不共享x,y轴，fig画布的大小为（13,8）\n",
    "    #当nrow=2,nclos=2时，代表画布被分为四个区域，其中axs[0][0]代表第一行第一个区域\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False, figsize=(13,8))\n",
    "    numberOfLabels = len(datingLabels)\n",
    "    LabelsColors = []\n",
    "    for i in datingLabels:\n",
    "        if i == 1:\n",
    "            LabelsColors.append('black')\n",
    "        if i == 2:\n",
    "            LabelsColors.append('orange')\n",
    "        if i == 3:\n",
    "            LabelsColors.append('red')\n",
    "    #绘制第一个散点图，以datingDataMat矩阵的第一（飞行常客历程）、第二列（玩游戏）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[0][0].scatter(x=datingDataMat[:, 0], y=datingDataMat[:,1], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[0][0].set_title(u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[0][0].set_xlabel(u'每年获得的飞行常客里程数',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[0][0].set_ylabel(u'玩视频游戏所消耗时间占',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    \n",
    "    \n",
    "    #绘制第二个散点图，以datingDataMat矩阵的第一（飞行常客历程）、第三列（冰激凌）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[0][1].scatter(x=datingDataMat[:, 0], y=datingDataMat[:,2], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[0][1].set_title(u'每年获得的飞行常客里程数与每周消费的冰激淋公升数',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[0][1].set_xlabel(u'每年获得的飞行常客里程数',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[0][1].set_ylabel(u'每周消费的冰激淋公升数',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    \n",
    "    #绘制第三个散点图，以datingDataMat矩阵的第二（玩游戏）、第三列（冰激凌）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[1][0].scatter(x=datingDataMat[:, 1], y=datingDataMat[:,2], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[1][0].set_title(u'玩视频游戏所消耗时间占比与每周消费的冰激淋公升数',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[1][0].set_xlabel(u'玩视频游戏所消耗时间占比',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[1][0].set_ylabel(u'每周消费的冰激淋公升数',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    #打开的文件名\n",
    "    filename = \"K_NNData.txt\"\n",
    "    #打开并处理数据\n",
    "    datingDataMat, datingLabels = file2matrix(filename)\n",
    "    showdatas(datingDataMat, datingLabels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.数据准备：归一化处理\n",
    "如下表给出了四组样本，如果要计算样本3和样本4的距离，可以使用欧拉公式计算。\n",
    "> 表2.1约会网站样本数据\n",
    "\n",
    "| 样本     | 玩游戏所耗费时间百分比| 每年获得的飞行常用里程数 | 每周消耗的冰激凌公升数| 样本分类|\n",
    "|--------|---------|---------|:-------:|--------:|\n",
    "| 1| 0.8|400| 0.5      |1|\n",
    "| 2| 12| 134000 |0.9      |3|\n",
    "| 3| 0| 20000 | 1.1    |2|\n",
    "| 4| 67| 32000 | 0.1    |2|\n",
    "\n",
    "计算方法如图2-1所示\n",
    "> 计算公式\n",
    "$$\\sqrt{(0-67)^2+(20000-32000)^2+(1.1-0.1)^2}$$\n",
    "\n",
    "如上计算公式可以看出来飞行里程数的数值比较大，会影响其他特征的占比，但是三种特征是一样重要的。\n",
    "在处理这种不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为０到１或者-１到１之间。下面的公式可以将任意取值范围的特征值转化为０到１区间内的值：\n",
    "\n",
    "*newValue* = *(oldValue-min)*/*(max-min)*\n",
    "\n",
    "其中min和max分别是数据集中的最小特征值和最大特征值。虽然改变数值取值范围增加了分类器的复杂度，但为了得到准确结果，我们必须这样做。下面函数自动将数据归一化。代码如下：\n",
    "- `np.tile()` 是一种元素复制方法，比如`a = [1,2]`,则 `np.tile(a, 2)` 结果为`a = [1,2,1,2]`,更高级的 `np.tile(a, [4,1])`结果变成 `4x1` 的矩阵`[[1,2],[1,2],[1,2],[1,2]]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "函数说明:对数据进行归一化\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 特征矩阵\n",
    "Returns:\n",
    "    normDataSet - 归一化后的特征矩阵\n",
    "    ranges - 数据范围\n",
    "    minVals - 数据最小值\n",
    "\"\"\"\n",
    "def autoNorm(dataSet):\n",
    "    #获得数据的最值\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    #最大值和最小值的差值\n",
    "    ranges = maxVals - minVals\n",
    "    #shape(dataSet)返回dataSet矩阵的行列数,此时normDataSet是[100x3]的0矩阵\n",
    "    normDataSet = np.zeros(np.shape(dataSet))\n",
    "    #返回dataSet的行数\n",
    "    m = dataSet.shape[0]\n",
    "    #原始值减去最小值，np.tile（）是矩阵复制的一种方法，作用是将minVals复制成为m行1列的矩阵\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "    #除以最大值和最小值之差，得到归一数据\n",
    "    normDataSet = normDataSet / np.tile(ranges, (m,1))\n",
    "    #返回归一化数据结果，数据范围和最小值\n",
    "    return normDataSet, ranges, minVals\n",
    "\n",
    "filename = \"K_NNData.txt\"\n",
    "#处理数据\n",
    "datingDataMat, datingLabels = file2matrix(filename)\n",
    "normDataSet, ranges, minVals = autoNorm(datingDataMat)\n",
    "print(normDataSet) #1000x3\n",
    "print(ranges) #1x3\n",
    "print(minVals) #1x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.测试算法：验证分类器性能\n",
    "机器学习算法一个很重要的工作就是评估算法的正确率，通常我们只提供已有数据的90%作为训练样本来训练分类器，而使用其余的10%数据去测试分类器，检测分类器的正确率。需要注意的是，10%的测试数据应该是随机选择的，由于海伦提供的数据并没有按照特定目的来排序，所以我么你可以随意选择10%数据而不影响其随机性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "函数说明:kNN算法,分类器\n",
    "\n",
    "Parameters:\n",
    "    inX - 用于分类的数据(测试集)\n",
    "    dataSet - 用于训练的数据(训练集)\n",
    "    labes - 分类标签\n",
    "    k - kNN算法参数,选择距离最小的k个点\n",
    "Returns:\n",
    "    sortedClassCount[0][0] - 分类结果\n",
    "\"\"\"\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    #numpy函数shape[0]返回dataSet的行数\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    #在列向量方向上重复inX共1次（横向）,行向量方向重复inX共dataSetSize次\n",
    "    #inX  [1x3] np.tile(inX, (dataSetSize, 1))变为[dataSetSize x 3]\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    #二维特征相减后平方\n",
    "    sqDiffMat = diffMat**2\n",
    "    #sum()所有元素相加，sum(0)列相加，sum(1)行相加\n",
    "    sqDistance = sqDiffMat.sum(axis=1)\n",
    "    #开方 计算处距离\n",
    "    distances = sqDistance**0.5\n",
    "    #返回distances中元素从小到大排序后的索引值\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    #定义一个记录类别次数的字典\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        #取前k个元素的类别\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        #计算类别次数\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    #key=operator.itemgetter(1)根据字典的值进行排序\n",
    "    #key=operator.itemgetter(0)根据字典的键进行排序\n",
    "    #reverse降序排序字典\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #返回次数最多的类别,即所要分类的类别\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "\"\"\"\n",
    "函数说明:分类器测试函数\n",
    "\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    normDataSet - 归一化后的特征矩阵\n",
    "    ranges - 数据范围\n",
    "    minVals - 数据最小值\n",
    "\"\"\"\n",
    "def datingClassTest():\n",
    "    #打开文件\n",
    "    filename = \"K_NNData.txt\"\n",
    "    #将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中\n",
    "    datingDataMat, datingLabels = file2matrix(filename)\n",
    "    #去除所有数据的百分之十\n",
    "    hoRatio = 0.10\n",
    "    #数据归一化\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    #获得normMat的行数\n",
    "    m = normMat.shape[0]\n",
    "    #百分之十的测试数据的个数\n",
    "    numTestVecs = int(m * hoRatio)\n",
    "    #分类错误计数\n",
    "    errorCount = 0.0\n",
    "    \n",
    "    for i in range(numTestVecs):\n",
    "        #前numTestVecs个数据作为测试集，后m-numTestVecs个数据作为训练集\n",
    "        classifierResult = classify0(normMat[i, :], normMat[numTestVecs:m, :],\n",
    "                                    datingLabels[numTestVecs:m], 4)\n",
    "        print(\"分类结果：%d\\t真实结果:%d\" %(classifierResult, datingLabels[i]))\n",
    "        if classifierResult != datingLabels[i]:\n",
    "            errorCount += 1.0\n",
    "    print(\"错误率：%f%%\" %(errorCount/float(numTestVecs)*100))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    datingClassTest()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证分类器结果中可以看出，错误率是4%，这是一个不错的结果。我们可以改变函数datingClassTest内变量hoRatio和分类器k的值，检测错误率是否随着变量值的变化而增加。依赖于分类算法、数据集和程序设置，分类器的输出结果可能有很大的不同。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.构建完整可用系统\n",
    "我们可以给海伦一个小段程序，通过该程序海伦会在约会网站上找到某个人并输入他的信息。程序会给出她对男方喜欢程度的预测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*- coding: UTF-8 -*-\n",
    "import numpy as np\n",
    "import operator\n",
    "\"\"\"\n",
    "函数说明:打开并解析文件，对数据进行分类：1代表不喜欢,2代表魅力一般,3代表极具魅力\n",
    "\n",
    "Parameters:\n",
    "    filename - 文件名\n",
    "Returns:\n",
    "    returnMat - 特征矩阵\n",
    "    classLabelVector - 分类Label向量\n",
    "\"\"\"\n",
    "def file2matrix(filename):\n",
    "    #打开文件\n",
    "    fr = open(filename)\n",
    "    #读取文件所有内容\n",
    "    array0Lines = fr.readlines()\n",
    "    #得到文件行数\n",
    "    numberOfLines = len(array0Lines)\n",
    "    #定义返回矩阵，解析完成的数据：numberOfLines行，3列\n",
    "    returnMat = np.zeros((numberOfLines, 3))\n",
    "    #返回分类标签向量\n",
    "    classLabelVector = []\n",
    "    #行的索引值\n",
    "    index = 0\n",
    "    for line in array0Lines:\n",
    "        #s.strip(rm)，当rm空时,默认删除头尾空白符(包括'\\n','\\r','\\t',' ')\n",
    "        line = line.strip()\n",
    "        #使用s.split(str=\"\",num=string,cout(str))将字符串根据'\\t'分隔符进行切片\n",
    "        listFromLine = line.split('\\t')\n",
    "        #将数据前三列提取出来,存放到returnMat的NumPy矩阵中,也就是特征矩阵\n",
    "        returnMat[index, :] = listFromLine[0:3]\n",
    "       #根据文本中标记的喜欢的程度进行分类,1代表不喜欢,2代表魅力一般,3代表极具魅力\n",
    "        if listFromLine[-1] == 'didntLike':\n",
    "            classLabelVector.append(1)\n",
    "        elif listFromLine[-1] == 'smallDoses':\n",
    "            classLabelVector.append(2)\n",
    "        elif listFromLine[-1] == 'largeDoses':\n",
    "            classLabelVector.append(3)\n",
    "        index += 1\n",
    "    return returnMat, classLabelVector \n",
    "\n",
    "from matplotlib.font_manager import FontProperties\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "函数说明:可视化数据\n",
    "\n",
    "Parameters:\n",
    "    datingDataMat - 特征矩阵\n",
    "    datingLabels - 分类Label\n",
    "Returns:\n",
    "    无\n",
    "Modify:\n",
    "    2017-03-24\n",
    "\"\"\"\n",
    "def showdatas(datingDataMat, datingLabels):\n",
    "    #设置汉字格式\n",
    "    font = FontProperties(fname=r\"/usr/share/fonts/truetype/arphic/ukai.ttc\")\n",
    "    #将fig画布分隔成1行1列，不共享x,y轴，fig画布的大小为（13,8）\n",
    "    #当nrow=2,nclos=2时，代表画布被分为四个区域，其中axs[0][0]代表第一行第一个区域\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, sharex=False, sharey=False, figsize=(13,8))\n",
    "    numberOfLabels = len(datingLabels)\n",
    "    LabelsColors = []\n",
    "    for i in datingLabels:\n",
    "        if i == 1:\n",
    "            LabelsColors.append('black')\n",
    "        if i == 2:\n",
    "            LabelsColors.append('orange')\n",
    "        if i == 3:\n",
    "            LabelsColors.append('red')\n",
    "    #绘制第一个散点图，以datingDataMat矩阵的第一（飞行常客历程）、第二列（玩游戏）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[0][0].scatter(x=datingDataMat[:, 0], y=datingDataMat[:,1], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[0][0].set_title(u'每年获得的飞行常客里程数与玩视频游戏所消耗时间占比',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[0][0].set_xlabel(u'每年获得的飞行常客里程数',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[0][0].set_ylabel(u'玩视频游戏所消耗时间占',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    \n",
    "    \n",
    "    #绘制第二个散点图，以datingDataMat矩阵的第一（飞行常客历程）、第三列（冰激凌）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[0][1].scatter(x=datingDataMat[:, 0], y=datingDataMat[:,2], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[0][1].set_title(u'每年获得的飞行常客里程数与每周消费的冰激淋公升数',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[0][1].set_xlabel(u'每年获得的飞行常客里程数',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[0][1].set_ylabel(u'每周消费的冰激淋公升数',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    \n",
    "    #绘制第三个散点图，以datingDataMat矩阵的第二（玩游戏）、第三列（冰激凌）数据画散点图，\n",
    "    #散点图大小为15，透明度0.5\n",
    "    axs[1][0].scatter(x=datingDataMat[:, 1], y=datingDataMat[:,2], \n",
    "                      color=LabelsColors, s=15, alpha=0.5)\n",
    "    #设置标题 x轴label y轴label\n",
    "    axs0_title_text = axs[1][0].set_title(u'玩视频游戏所消耗时间占比与每周消费的冰激淋公升数',\n",
    "                                         FontProperties=font)\n",
    "    axs0_xlabel_text = axs[1][0].set_xlabel(u'玩视频游戏所消耗时间占比',\n",
    "                                           FontProperties=font)\n",
    "    axs0_ylabel_text = axs[1][0].set_ylabel(u'每周消费的冰激淋公升数',\n",
    "                                           FontProperties=font)\n",
    "    plt.setp(axs0_title_text, size=9, weight='bold', color='red')\n",
    "    plt.setp(axs0_xlabel_text, size=7, weight='bold', color='black')\n",
    "    plt.setp(axs0_ylabel_text, size=7, weight='bold', color='black')\n",
    "    plt.show()\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "函数说明:对数据进行归一化\n",
    "\n",
    "Parameters:\n",
    "    dataSet - 特征矩阵\n",
    "Returns:\n",
    "    normDataSet - 归一化后的特征矩阵\n",
    "    ranges - 数据范围\n",
    "    minVals - 数据最小值\n",
    "\"\"\"\n",
    "def autoNorm(dataSet):\n",
    "    #获得数据的最值\n",
    "    minVals = dataSet.min(0)\n",
    "    maxVals = dataSet.max(0)\n",
    "    #最大值和最小值的差值\n",
    "    ranges = maxVals - minVals\n",
    "    #shape(dataSet)返回dataSet矩阵的行列数,此时normDataSet是[100x3]的0矩阵\n",
    "    normDataSet = np.zeros(np.shape(dataSet))\n",
    "    #返回dataSet的行数\n",
    "    m = dataSet.shape[0]\n",
    "    #原始值减去最小值，np.tile（）是矩阵复制的一种方法，作用是将minVals复制成为m行1列的矩阵\n",
    "    normDataSet = dataSet - np.tile(minVals, (m, 1))\n",
    "    #除以最大值和最小值之差，得到归一数据\n",
    "    normDataSet = normDataSet / np.tile(ranges, (m,1))\n",
    "    #返回归一化数据结果，数据范围和最小值\n",
    "    return normDataSet, ranges, minVals\n",
    "\n",
    "\"\"\"\n",
    "函数说明:kNN算法,分类器\n",
    "\n",
    "Parameters:\n",
    "    inX - 用于分类的数据(测试集)\n",
    "    dataSet - 用于训练的数据(训练集)\n",
    "    labes - 分类标签\n",
    "    k - kNN算法参数,选择距离最小的k个点\n",
    "Returns:\n",
    "    sortedClassCount[0][0] - 分类结果\n",
    "\"\"\"\n",
    "def classify0(inX, dataSet, labels, k):\n",
    "    #numpy函数shape[0]返回dataSet的行数\n",
    "    dataSetSize = dataSet.shape[0]\n",
    "    #在列向量方向上重复inX共1次（横向）,行向量方向重复inX共dataSetSize次\n",
    "    #inX  [1x3] np.tile(inX, (dataSetSize, 1))变为[dataSetSize x 3]\n",
    "    diffMat = np.tile(inX, (dataSetSize, 1)) - dataSet\n",
    "    #二维特征相减后平方\n",
    "    sqDiffMat = diffMat**2\n",
    "    #sum()所有元素相加，sum(0)列相加，sum(1)行相加\n",
    "    sqDistance = sqDiffMat.sum(axis=1)\n",
    "    #开方 计算处距离\n",
    "    distances = sqDistance**0.5\n",
    "    #返回distances中元素从小到大排序后的索引值\n",
    "    sortedDistIndices = distances.argsort()\n",
    "    #定义一个记录类别次数的字典\n",
    "    classCount = {}\n",
    "    for i in range(k):\n",
    "        #取前k个元素的类别\n",
    "        voteIlabel = labels[sortedDistIndices[i]]\n",
    "        #计算类别次数\n",
    "        classCount[voteIlabel] = classCount.get(voteIlabel, 0) + 1\n",
    "    #key=operator.itemgetter(1)根据字典的值进行排序\n",
    "    #key=operator.itemgetter(0)根据字典的键进行排序\n",
    "    #reverse降序排序字典\n",
    "    sortedClassCount = sorted(classCount.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    #返回次数最多的类别,即所要分类的类别\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "\"\"\"\n",
    "函数说明:分类器测试函数\n",
    "\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    normDataSet - 归一化后的特征矩阵\n",
    "    ranges - 数据范围\n",
    "    minVals - 数据最小值\n",
    "\"\"\"\n",
    "def datingClassTest():\n",
    "    #打开文件\n",
    "    filename = \"K_NNData.txt\"\n",
    "    #将返回的特征矩阵和分类向量分别存储到datingDataMat和datingLabels中\n",
    "    datingDataMat, datingLabels = file2matrix(filename)\n",
    "    #去除所有数据的百分之十\n",
    "    hoRatio = 0.10\n",
    "    #数据归一化\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    #获得normMat的行数\n",
    "    m = normMat.shape[0]\n",
    "    #百分之十的测试数据的个数\n",
    "    numTestVecs = int(m * hoRatio)\n",
    "    #分类错误计数\n",
    "    errorCount = 0.0\n",
    "    \n",
    "    for i in range(numTestVecs):\n",
    "        #前numTestVecs个数据作为测试集，后m-numTestVecs个数据作为训练集\n",
    "        classifierResult = classify0(normMat[i, :], normMat[numTestVecs:m, :],\n",
    "                                    datingLabels[numTestVecs:m], 4)\n",
    "        print(\"分类结果：%d\\t真实结果:%d\" %(classifierResult, datingLabels[i]))\n",
    "        if classifierResult != datingLabels[i]:\n",
    "            errorCount += 1.0\n",
    "    print(\"错误率：%f%%\" %(errorCount/float(numTestVecs)*100))\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "函数说明:通过输入一个人的三维特征,进行分类输出\n",
    "\n",
    "Parameters:\n",
    "    无\n",
    "Returns:\n",
    "    无\n",
    "\"\"\"\n",
    "def classifyPerson():\n",
    "    #输出结果\n",
    "    resultList = ['讨厌', '有些喜欢', '十分喜欢']\n",
    "    #三维特征用户输入\n",
    "    precentTats = float(input(\"玩游戏所耗时间百分比:\"))\n",
    "    ffMiles = float(input(\"每年获得的飞行常客的里程数:\"))\n",
    "    iceCream = float(input(\"每周消费的冰激凌公升数:\"))\n",
    "    #打开文件\n",
    "    filename = \"K_NNData.txt\"\n",
    "    #处理文件\n",
    "    datingDataMat, datingLabels = file2matrix(filename)\n",
    "    #训练集归一化\n",
    "    normMat, ranges, minVals = autoNorm(datingDataMat)\n",
    "    #测试数据生成numpy数组\n",
    "    inArr = np.array([precentTats, ffMiles, iceCream])\n",
    "    #测试集归一化\n",
    "    normArr = (inArr - minVals) / ranges\n",
    "    #返回分类结果\n",
    "    classifierResult = classify0(normArr, normMat, datingLabels, 4)\n",
    "    #打印结果\n",
    "    print(\"你可能 %s 这个人\" %(resultList[classifierResult-1]))\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    classifyPerson()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
